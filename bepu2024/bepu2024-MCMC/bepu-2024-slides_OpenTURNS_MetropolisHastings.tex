% Copyright (C) 2022 - Joseph Mur√©

\documentclass{beamer}

%\setbeameroption{hide notes}
%\setbeameroption{show notes}
%\setbeameroption{show only notes}

\include{macros}

\usepackage[
backend=biber,
style=alphabetic,
sorting=ynt
]{biblatex}

\usepackage{tikz}
\usetikzlibrary{positioning}

\usepackage{subcaption}

\renewcommand{\footnotesize}{\tiny}

\title[OpenTURNS]{Bayesian inference using MCMC in OpenTURNS }

\author[Mur\'e]{
E. Songo \inst{1} \and
J. Mur\'e \inst{1} \and
M. Keller \inst{1}
}

\institute[EDF]{
\inst{1} EDF R\&D. 6, quai Watier, 78401, Chatou Cedex - France, joseph.mure@edf.fr \and %
}

\date[]{May 20th 2024, BEPU 2024, Lucca (Italy)}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
  escapechar={|},
  backgroundcolor=\color{backcolour},   commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\ttfamily\tiny,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b,
  keepspaces=true,
  numbers=left,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  tabsize=1,
  numbers=none
}

\newcommand{\target}[1]{\textcolor{red}{#1}}
\newcommand{\proposal}[1]{\textcolor{blue}{#1}}
\newcommand{\support}[1]{\textcolor{orange}{#1}}
\newcommand{\prior}[1]{\textcolor{red}{#1}}
\newcommand{\likelihood}[1]{\textcolor{green}{#1}}
\newcommand{\observation}[1]{\textcolor{orange}{#1}}



\lstset{style=mystyle, language=python}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  \begin{document}

  \begin{frame}
    \titlepage

    \begin{columns}
      \column{0.45\textwidth}
      \centering
      \includegraphics[height=0.15\textheight]{figures/logo-openturns.png}

      \column{0.45\textwidth}
      \centering
      \includegraphics[height=0.15\textheight]{figures/edf.jpg}

     \end{columns}

    \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{About OpenTURNS}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \begin{frame}[containsverbatim]
        \frametitle{OpenTURNS: \url{www.openturns.org}}

      \begin{scriptsize}

      \begin{minipage}[t]{0.33\textwidth}
      \begin{itemize}
      \item Data analysis
      \begin{itemize}
      \tiny
      \item Distribution fitting
      \item Statistical tests
      \item Estimate dependency and copulas
      \item Estimate stochastic processes
      \end{itemize}
      \end{itemize}
      \end{minipage}%
      \begin{minipage}[t]{0.33\textwidth}
      \begin{itemize}
      \item Probabilistic modeling
      \begin{itemize}
      \tiny
      \item Dependence modeling
      \item Univariate distributions
      \item Multivariate distrbutions
      \item Copulas
      \item Processes
      \item Covariance kernels
      \end{itemize}
      \end{itemize}
      \end{minipage}%
      \begin{minipage}[t]{0.33\textwidth}
      \begin{itemize}
      \item Surrogate models
      \begin{itemize}
      \tiny
      \item Linear regression
      \item Polynomial chaos expansion
      \item Gaussian  process regression
      \item Spectral methods
      \item Low rank tensors
      \item Fields metamodel
      \end{itemize}
      \end{itemize}
      \end{minipage}

      \vspace{20pt}

      \begin{minipage}[t]{0.33\textwidth}
      \begin{itemize}
      \item Reliability, sensitivity
      \begin{itemize}
      \tiny
      \item Sampling methods
      \item Approximation methods
      \item Sensitivity analysis
      \item Design of experiments
      \end{itemize}
      \end{itemize}
      \end{minipage}%
      \begin{minipage}[t]{0.33\textwidth}
      \begin{itemize}
      \item Calibration
      \begin{itemize}
      \tiny
      \item Least squares calibration
      \item Gaussian calibration
      \item Bayesian calibration
      \end{itemize}
      \end{itemize}
      \end{minipage}%
      \begin{minipage}[t]{0.33\textwidth}
      \begin{itemize}
      \item Numerical methods
      \begin{itemize}
      \tiny
      \item Optimization
      \item Integration
      \item Least squares
      \item Meshing
      \item Coupling with external codes
      \end{itemize}
      \end{itemize}
      \end{minipage}
      \end{scriptsize}

      \begin{tabular}{@{}c@{}c@{}c@{}c@{}c@{}}
      \includegraphics[width=0.2\textwidth]{figures/plot_kriging.png}&
      \includegraphics[width=0.2\textwidth]{figures/plot_random_walk.png}&
      \includegraphics[width=0.2\textwidth]{figures/plot_sobol_field.png}&
      \includegraphics[width=0.2\textwidth]{figures/plot_monte_carlo.png}&
      \includegraphics[width=0.2\textwidth]{figures/plot_distribution_fitting.png}
      \end{tabular}
    \end{frame}


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \begin{frame}[containsverbatim]
      \frametitle{Coupling OpenTURNS with computer codes}

      \small

      OpenTURNS provides a text file exchange based interface in order to perform analyses on complex computer codes

      \vspace{10pt}

      \begin{columns}
          \column{0.6\textwidth}

      \centering

      \includegraphics[width=1.\textwidth]{figures/Coupling.png}

          \column{0.4\textwidth}

      \begin{itemize}
      \item Replaces the need for input/output text parsers
      \item Wraps a simulation code under the form of a standard python function
      \item Allows to interface OpenTURNS with a cluster
      \item \href{https://openturns.github.io/otwrapy/master/index.html}{otwrapy}: interfacing tool to allow easy parallelization
      \end{itemize}

      \end{columns}

    \end{frame}

\begin{frame}
    \frametitle{Contents}
    \tableofcontents
    \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Metropolis-Hastings algorithm}
\begin{frame}[containsverbatim]
    \frametitle{OpenTURNS: Metropolis-Hastings}
    \small
    We want to sample from the distribution $\target{\pi}$ of a random variables $X$.
    Here is one step of the algorithm, starting from the point $x$:

    \begin{enumerate}
    \item Simulate a candidate $x' \sim \proposal{q( \cdot | x)}$ for some conditional distribution $q$.
    \item Compute
    $
    \alpha(x' | x,y,z) = \min \left\{ \frac{\target{\pi(x')} \, \proposal{q(x | x')}}{\target{\pi(x)} \proposal{q(x' | x)}} , 1 \right\}.
    $
    \item Simulate $u \sim \mathcal{U}(0,1)$. If $u \leqslant \alpha(x'| x)$,
    then the next state is $x'$, otherwise it is $x$.
    \end{enumerate}

    Throughout the presentation, our code is prefaced by:

    \begin{lstlisting}
    import openturns as ot
    import math as m
    import numpy as np
    \end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Random walk Metropolis-Hastings}
\begin{frame}[containsverbatim]{Random walk Metropolis Hastings}

    When $q(\cdot | x) = x + \proposal{\mu}$, where $\proposal{\mu}$ is a distribution that does not depend on $x$,
    the  algorithm is called ``Random walk Metropolis-Hastings'' and $\proposal{}\mu$ is called the ``proposal distribution''.


    \begin{block}{Sample from a nonstandard distribution\footnote{Marin , J.M. and Robert, C.P. (2007). Bayesian Core: A Practical Approach to Computational Bayesian Statistics. \emph{Springer-Verlag}, New York}}
        \begin{columns}
            \begin{column}{0.4\textwidth}
                \includegraphics[width=\textwidth]{figures/ChristianRobert_tough_density}
            \end{column}
            \begin{column}{0.6\textwidth}
                \vspace{-0.5cm}
                \begin{align*}
                    & \pi(x) \\ \propto & \frac{1}{2} \target{(2 + \sin(x)^2)} \\
                    & \target{\exp \left[- \left(2 + \cos(3x)^3 + \sin(2x)^3 \right) x \right]} \\
                    & \support{\mathbf{1}_{[0, 2 \pi]}(x)}
                \end{align*}
            \end{column}
        \end{columns}


\vspace{-0.4cm}
\begin{lstlisting}
|\target{logdensity}| = ot.|Symbolic\target{Function}|('x','log(2+sin(x)^2) - (2+cos(3*x)^3+sin(2*x)^3) * x')
|\support{support = ot.Interval([0.0], [2.0 * m.pi])}|
|\proposal{proposal = ot.Normal(0.0, 2.0)}| # mu
initialState = [3.0]
sampler = ot.RandomWalkMetropolisHastings(|\target{logdensity}|, |\support{support}|, initialState, |\proposal{proposal}|)
x = sampler.getSample(10000)
\end{lstlisting}
    \end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[containsverbatim]{2D Random walk Metropolis Hastings}

    \begin{block}{Sample from a 2D nonstandard distribution}
        \begin{columns}
            \begin{column}{0.4\textwidth}
                \includegraphics[width=\textwidth]{figures/2d}
            \end{column}
            \begin{column}{0.6\textwidth}
                \vspace{-0.5cm}
                \begin{align*}
                    & \pi(x) \\ \propto & \target{\left( \exp\left[-\frac{1}{4} (x-3)^2 + y^2\right] \right.}\\
                    & \target{ \left. + \exp\left[-(x-5)^2 - 5 \left(y-\frac{1}{5} \right)^2 \right] \right) }\\
                    & \; \support{\mathbf{1}_{[0, 2 \pi]}(x)} \support{\mathbf{1}_{[0, 1]}(y)}
                \end{align*}
            \end{column}
        \end{columns}



\begin{lstlisting}
|\target{logdensity}| = ot.|Symbolic\target{Function}|(
    ["x", "y"], ["log(exp(-0.25 * (x-3)^2 + y^2) + exp(-(x-5)^2 - 5 * (y-0.2)^2))"]
)
|\support{support = ot.Interval([0.0, 0.0], [2.0 * m.pi, 1.0])}|
|\proposal{proposal = ot.Normal([0.0] * 2, [1.0, 0.2])}|
initialState = [3.0, 0.8]
sampler = ot.RandomWalkMetropolisHastings(|\target{logdensity}|, |\support{support}|, initialState, |\proposal{proposal}|)
x = sampler.getSample(50000)
\end{lstlisting}
    \end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[containsverbatim]{2D Random walk Metropolis Hastings in a Bayesian setting}

    \begin{block}{Posterior distribution of the parameters of a Weibull model}
        \begin{columns}
            \begin{column}{0.4\textwidth}
                \includegraphics[width=\textwidth]{figures/fiabilite}
            \end{column}
            \begin{column}{0.6\textwidth}
                \vspace{-0.5cm}
                \begin{align*}
                    \beta &\sim \prior{\Gamma(k=2, \lambda=2\cdot 10^{-4})} \\
                    \alpha &\sim \prior{\mathcal{U}(0.5, 3.8)} \\
                    \observation{T} | \beta, \alpha &\sim \likelihood{\mathcal{W}}(\beta, \alpha, 0) \\
                    F_{\mathcal{W}}(t) &= 1 - \exp \left[ - \left( \frac{t - 0}{\beta}\right)^\alpha\right]
                \end{align*}
            \end{column}
        \end{columns}



\begin{lstlisting}
alpha_min, alpha_max, a_beta, b_beta = 0.5, 3.8, 2.0, 2.0e-4
priorMarginals = [ot.|\prior{Gamma}|(a_beta, b_beta), ot.|\prior{Uniform}|(alpha_min, alpha_max)]
|\target{prior}| = ot.ComposedDistribution(priorMarginals)
|\proposal{proposal}| = ot.Normal([0.0]*2, [0.1*m.sqrt(a_beta/b_beta**2), 0.1*(alpha_max-alpha_min)])
initialState = [a_beta / b_beta, 0.5 * (alpha_max - alpha_min)]
sampler = ot.RandomWalkMetropolisHastings(|\target{prior}|, initialState, |\proposal{proposal}|)

|\likelihood{conditional} = ot.\likelihood{WeibullMin()}|
|\observation{Tobs}| = [[4380], [1791], [1611], [1291]]

# WeibullMin expects beta, alpha, and localization, but the prior is only on beta, alpha
linkFunction = ot.SymbolicFunction(["beta", "alpha"], ["beta", "alpha", "0"])
sampler.setLikelihood(|\likelihood{conditional}|, |\observation{Tobs}|, linkFunction)
sample = sampler.getSample(100000)
\end{lstlisting}
\end{block}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Gibbs algorithm}
\begin{frame}[containsverbatim]{A flood model}

%    \begin{block}{Model description}
        \begin{columns}
            \begin{column}{0.35\textwidth}
                \includegraphics[width=\textwidth]{figures/flooding_section}
                \begin{align*}
                    &\forall \, 1 \leq i  \leq 8, \observation{H^{(i)}} \sim \\
                      \likelihood{\mathcal{N}} &\left(G(\observation{Q^{(i)}}, K_s, Z_v, Z_m), \frac{1}{2}\right)
                \end{align*}
            \end{column}
            \begin{column}{0.65\textwidth}
                \begin{lstlisting}
|\observation{Qobs} = [[2097], [1448], [1516], [2173], [387], [3016], [651], [541]]|
|\observation{Hobs} = [[3.4], [2.5], [2.7], [3.5], [1.0], [4.2], [1.6], [1.6]]|

def flooding(X):
    L = 5.0e3
    B = 300.0
    Q, K_s, Z_v, Z_m = X
    alpha = (Z_m - Z_v) / L
    if alpha < 0.0 or K_s <= 0.0:
        H = np.inf
    else:
        H = (Q / (K_s * B * np.sqrt(alpha))) ** (3.0 / 5.0)
    return [H, 0.5]

functionG = ot.PythonFunction(4, 2, flooding)

# Q (input #0) is not calibrated
linkFunction = ot.ParametricFunction(functionG, |\observation{[0]}|, |[100]|)
                \end{lstlisting}
            \end{column}
        \end{columns}


%\end{block}

%\begin{block}{Prior description}
    \begin{columns}
        \begin{column}{0.36\textwidth}
            \begin{align*}
                \prior{K_s} \, &\prior{\sim \mathcal{N}(20, 5)} \\
                \prior{Z_v} \, &\prior{\sim \mathcal{N}(49, 1)} \\
                \prior{Z_m} \, &\prior{\sim \mathcal{N}(51, 1)}
            \end{align*}
        \end{column}
        \begin{column}{0.64\textwidth}
            \begin{lstlisting}
|\likelihood{conditional}| = |ot.\likelihood{Normal()}|

parameterPriorMean = [20.0, 49.0, 51.0]
parameterPriorSigma = [5.0, 1.0, 1.0]
|\prior{prior}| = |ot.\prior{Normal(parameterPriorMean, parameterPriorSigma)}|

initialState = parameterPriorMean
            \end{lstlisting}
        \end{column}
    \end{columns}

%\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}[containsverbatim]
    \frametitle{Single component Random Walk Metropolis-Hastings}
    \centering
    \vspace{0.5cm}
    \begin{tikzpicture}[
    squarednode/.style={rectangle, draw=green!60, fill=green!5, very thick, minimum size=5mm},
    ]
    %Nodes
    \node[squarednode]      (mhx)                              {\texttt{mh\_Ks}};
    \node[squarednode]      (mhy)       [right=of mhx] {{\texttt{mh\_Zv}}};
    \node[squarednode]      (mhz)       [right=of mhy] {{\texttt{mh\_Zm}}};

    %Lines
    \draw[->] (mhx.east) -- (mhy.west);
    \draw[->] (mhy.east) -- (mhz.west);
    \draw[->] (mhz.east) to [out=340,in=200,looseness=1] (mhx.west);
    \end{tikzpicture}

    \begin{lstlisting}
mh_coll = [
  ot.RandomWalkMetropolisHastings(|\prior{prior}|, initialState, |ot.\proposal{Uniform(-5.0, 5.0)}|, [0]),
  ot.RandomWalkMetropolisHastings(|\prior{prior}|, initialState, |ot.\proposal{Uniform(-1.0, 1.0)}|, [1]),
  ot.RandomWalkMetropolisHastings(|\prior{prior}|, initialState, |ot.\proposal{Uniform(-1.0, 1.0)}|, [2]),
]

for mh in mh_coll:
    mh.setLikelihood(|\likelihood{conditional}|, |\observation{Hobs}|, linkFunction, |\observation{Qobs}|)

sampler = ot.Gibbs(mh_coll) # NB: the order can be made random: cf. setUpdatingMethod
sample = sampler.getSample(10000)
    \end{lstlisting}

    \begin{figure}
    \includegraphics[width=0.32\textwidth]{figures/crue_gibbs_scmh_Z_v_K_s.pdf}
    \includegraphics[width=0.32\textwidth]{figures/crue_gibbs_scmh_Z_m_K_s.pdf}
    \includegraphics[width=0.32\textwidth]{figures/crue_gibbs_scmh_Z_m_Z_v.pdf}
    \end{figure}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[containsverbatim]
    \frametitle{Blocks of components can be considered}
    \medskip
    \centering
    \vspace{0.25cm}
    \begin{tikzpicture}[
    squarednode/.style={rectangle, draw=green!60, fill=green!5, very thick, minimum size=5mm},
    ]
    %Nodes
    \node[squarednode]      (mhxy)                     {\texttt{mh\_Ks}};
    \node[squarednode]      (mhz)       [right=of mhxy] {\texttt{mh\_Zv\_Zm}};

    %Lines
    \draw[->] (mhxy.east) -- (mhz.west);
    \draw[->] (mhz.east) to [out=340,in=200,looseness=1.5] (mhxy.west);

    \end{tikzpicture}

    \begin{lstlisting}
mh_coll = [
  ot.RandomWalkMetropolisHastings(|\prior{prior}|, initialState, |ot.\proposal{Uniform(-5.0, 5.0)}|, [0]),
  ot.RandomWalkMetropolisHastings(|\prior{prior}|,
                                  initialState,
                                  ot.|\proposal{ComposedDistribution([ot.Uniform(-1.0,1.0)]*2)}|,
                                  [1, 2])
]
for mh in mh_coll:
    mh.setLikelihood(|\likelihood{conditional}|, |\observation{Hobs}|, linkFunction, |\observation{Qobs}|)
sampler = ot.Gibbs(mh_coll) # NB: the order can be made random: cf. setUpdatingMethod
sample = sampler.getSample(10000)
            \end{lstlisting}

            \begin{figure}
            \includegraphics[width=0.32\textwidth]{figures/crue_gibbs_blocs_Z_v_K_s.pdf}
            \includegraphics[width=0.32\textwidth]{figures/crue_gibbs_blocs_Z_m_K_s.pdf}
            \includegraphics[width=0.32\textwidth]{figures/crue_gibbs_blocs_Z_m_Z_v.pdf}
            \end{figure}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Independent Metropolis-Hastings}
\begin{frame}[containsverbatim]
    \frametitle{Independent Metropolis-Hastings: $q(\cdot | x) = \mu$}
\begin{columns}
    \begin{column}{0.4\textwidth}
        \includegraphics[width=\textwidth]{figures/instrumental}
    \end{column}
    \begin{column}{0.6\textwidth}
        \begin{lstlisting}
|\target{logdensity}| = ot.|Symbolic\target{Function}|('x','...') # replace ...
|\support{support = ot.Interval([0.0], [2.0 * m.pi])}|
initialState = [3.0] # unimportant for independent MH

exp = ot.Exponential(1.0)
unif = ot.Normal(5.3, 0.4)
|\proposal{instrumental}| = |ot.\proposal{Mixture([exp, unif], [0.9, 0.1])}|

independentMH = ot.IndependentMetropolisHastings(
  |\target{logdensity}|, |\support{support}|, initialState, |\proposal{instrumental}|
)
x = independentMH.getSample(10000)
        \end{lstlisting}
    \end{column}
\end{columns}

\begin{columns}
    \begin{column}{0.46\textwidth}
        \includegraphics[width=\textwidth]{figures/randomwalkMH}
    \end{column}
    \begin{column}{0.46\textwidth}
        \includegraphics[width=\textwidth]{figures/independentMH}
    \end{column}
\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{User-defined Metropolis-Hastings}
\begin{frame}[containsverbatim]
    \frametitle{User-defined Metropolis-Hastings: $q(\cdot | x) = \mu(x)$}

    % \small With UserDefinedMetropolisHastings,
    % manually define the proposal mechanism.

    \begin{block}{Metropolis adjusted Langevin algorithm\footnote{
        Robert, C. P. \emph{The Metropolis-Hastings algorithm}. arXiv preprint arXiv:1504.01896, 2015} implementation}
        \begin{columns}
            \begin{column}{0.4\textwidth}
                \includegraphics[width=\textwidth]{figures/MALA}
            \end{column}
            \begin{column}{0.6\textwidth}
                With $h>0$ a fixed parameter:
                \begin{equation*}
                    \proposal{q(\cdot | x)} = \proposal{\mathcal{N}}\left(x + \frac{h}{2} \frac{d}{dx} [ \log(\pi(x) ], \sqrt{h} \right)
                \end{equation*}
            \end{column}
        \end{columns}
    \end{block}
\vspace{-0.4cm}
\begin{lstlisting}
from openturns.experimental import UserDefinedMetropolisHastings
|\target{logdensity}| = ot.|Symbolic\target{Function}|('x','log(2+sin(x)^2) - (2+cos(3*x)^3+sin(2*x)^3) * x')
|\support{support}, \proposal{proposal}, initialState| = |ot.\support{Interval([0.0], [2.0 * m.pi])}, ot.\proposal{Normal()}, [2.5]|
h = 0.5
std_deviation = m.sqrt(h)

def python_link(x):
    derivative_log_density = |\target{logdensity}|.getGradient().gradient(x)[0, 0]
    mean = x[0] + h / 2 * derivative_log_density
    return [mean, std_deviation]
|\proposal{link}| = ot.PythonFunction(1, 2, python_link)

mala = UserDefinedMetropolisHastings(|\target{logdensity}|, |\support{support}|, initialState, |\proposal{proposal}|, |\proposal{link}|)
z = mala.getSample(10000)
\end{lstlisting}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SLIDES EDIMAH

\section{Application}

\begin{frame}
  \frametitle{Application: airflow rate in a depressurized room}
  	\begin{minipage}{\textwidth}

        \begin{equation*}
            g(\xi, \textcolor{red}{\theta_0}, \textcolor{red}{\theta_1})
            =
            0.6 \times 3600 \times \textcolor{red}{\theta_0} \left( \frac{2}{1.8} \xi \right)^{\textcolor{red}{\theta_1}}
        \end{equation*}
 
  	\begin{minipage}{0.35\textwidth}
    For $1 \leqslant i \leqslant 233$:
    \begin{align}
    \begin{cases}
        \textcolor{blue}{X_i} &= \quad \xi_i + Z_i \quad \quad \quad  \quad\; \;  \\%\text{ with }  Z = 0 \text{ for the time being} \tag{\textbf{vacuum model}} \\ %\sim \mathcal{N}(0, \sigma_{Z}^2) \tag{\textbf{vacuum model}} \\
        \textcolor{blue}{Y_i} &= g(\xi_i, \textcolor{red}{\theta_0}, \textcolor{red}{\theta_1}) + E_i  \nonumber % \quad \text{ with } E \sim \mathcal{N}(0, \sigma_{E}^2) \text{, and } \sigma^2_{E} > 0
    \end{cases}
    \end{align}
	\end{minipage}
	\begin{minipage}{0.60\textwidth}
    	\begin{itemize}
    		\item Input: $\textcolor{blue}{X_i}$ (pressure difference -- \textit{bars})
    		\item Output: $\textcolor{blue}{Y_i}$ (airflow rate -- $m^3/h$) 
    		\item Parameter: $\textcolor{red}{\theta_0}$ (area -- $m^2$)
    		\item Parameter: $\textcolor{red}{\theta_1}$ (exponent)
    	\end{itemize}
	\end{minipage}

    \vspace{0.5cm}
    \begin{minipage}{0.45\textwidth}
        \begin{itemize}
            \item $Z_i \sim U(-0.05, 0.05)$
            \item $E_i \sim N(0, \sigma_E^2)$,  $\sigma_E^2 \sim 1 / \sigma_E^2$

        \end{itemize}
        \end{minipage}
        \begin{minipage}{0.45\textwidth}
            \begin{itemize}
                \item $\theta_0 \sim U(0,2)$
                \item $\theta_1 \sim U(0,2)$
            \end{itemize}
        \end{minipage}
	\end{minipage}
    \vspace{0.5cm}

Strategy: $\sigma_E^2$ averaged out analytically, the rest sampled using Gibbs with:
\begin{itemize}
    \item Random walk Metropolis-Hastings on $\textcolor{red}{\theta_0}$, step is tuned during burn-in.
    \item Random walk Metropolis-Hastings on $\textcolor{red}{\theta_1}$, step is tuned during burn-in.
    \item Independent MH on each $Z_i$ with the prior as proposal.
\end{itemize}

	\vspace{1cm}
	 

\end{frame}

\begin{frame}
    \frametitle{Convergence diagnostics for $\textcolor{red}{\theta_0}$, $\textcolor{red}{\theta_1}$, $\xi_1$ with 3 chains}

\vspace{-0.5cm}
    \begin{figure}[H]
        \centering
        
        \begin{subfigure}{0.3\textwidth}
            \centering
            \includegraphics[width=\linewidth]{figures/vacuum_lock_reduced_acf_plot_theta.png}
            \subcaption{ACF plot}
            \label{fig:vacuum_joint_acf}
        \end{subfigure}\hfill
        \begin{subfigure}{0.3\textwidth}
            \centering
            \includegraphics[width=\linewidth]{figures/vacuum_lock_reduced_trace_plot_theta.png}
            \subcaption{Trace plot}
            \label{fig:vacuum_joint_trace}
        \end{subfigure}\hfill
        \begin{subfigure}{0.32\textwidth}
            \centering
            \includegraphics[width=1.1\linewidth]{figures/vacuum_lock_reduced_convergence_plot.png}
            \subcaption{Convergence plot of ergodic means}
            \label{fig:vacuum_joint_convergence_plot}
        \end{subfigure}
    

    \end{figure}
\end{frame}


\begin{frame}
    \frametitle{Posterior distribution}

    \begin{figure}[H]
        \centering
            \includegraphics[width=0.5\textwidth]{figures/vacuum_lock_reduced_final_joint_prior_posterior_plot.png}\hfill
            \includegraphics[width=0.5\textwidth]{figures/vacuum_lock_reduced_final_joint_scatterplot_theta.png}
            \caption{Left: Prior and posterior distributions of $\textcolor{red}{\theta_0}$, $\textcolor{red}{\theta_1}$ and $\xi_1$. Right: Scatter plot of the sample of $(\textcolor{red}{\theta_0}, \textcolor{red}{\theta_1})$ from the joint \textcolor{blue}{posterior distribution (solid blue dots)}, from a \textcolor{darkgreen}{simplified posterior where all $Z_i = 0$ (transparent green dots)}, alongside the \textcolor{red}{Ordinary Least Squared estimator (red star)}}
            \label{fig:vacuum_joint_prior_posterior}
    \end{figure}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\begin{frame}
    \frametitle{Conclusion}
    OpenTURNS provides an MCMC sampling framework through the following classes:
    \begin{itemize}
        \item MetropolisHastings variants:
        \begin{itemize}
            \item RandomWalkMetropolisHastings
            \item IndependentMetropolisHastings
            \item UserDefinedMetropolisHastings
            \item RandomVectorMetropolisHastings (not shown in this presentation)
        \end{itemize}
        \item Gibbs
    \end{itemize}
    \medskip
    These classes can be freely combined to sample from nonstandard distributions
    in a ``smart'' manner. \medskip

    In a Bayesian setting, this framework allows users to create and implement
    the MCMC algorithm most suited to a particular posterior distribution.
\end{frame}
    \end{document}
